name: ğŸš€ Scraping Automatique Courir.com

on:
  schedule:
    - cron: '0 */6 * * *'  # â° Toutes les 6 heures
  workflow_dispatch:         # ğŸ® DÃ©clenchement manuel

jobs:
  scrape:
    runs-on: ubuntu-latest   # ğŸ’» Machine virtuelle Ubuntu
    timeout-minutes: 30      # â±ï¸ AugmentÃ© Ã  30 minutes pour plus de marge

    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_ROLE: ${{ secrets.SUPABASE_SERVICE_ROLE }}  # AlignÃ© avec scraper.py

    steps:
    # Ã‰tape 1: ğŸ“¥ TÃ©lÃ©charger le code
    - name: Checkout du code
      uses: actions/checkout@v4

    # Ã‰tape 2: ğŸ Installer Python
    - name: Installation de Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    # Ã‰tape 3: ğŸ“¦ Mettre en cache les dÃ©pendances Python
    - name: Cache des dÃ©pendances
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('scripts/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    # Ã‰tape 4: ğŸ“¦ Installer les dÃ©pendances
    - name: Installation des dÃ©pendances
      run: pip install -r scripts/requirements.txt

    # Ã‰tape 5: ğŸ•·ï¸ Lancer le scraping
    - name: ExÃ©cution du scraping
      run: |
        cd scripts
        python scraper.py || exit 1  # Exit avec erreur si le script Ã©choue
